全部采用mongo数据库

架构思想：
1：最后会成为异步爬虫
2：一个进程负责从数据库获取任务，并更新任务状态，然后将任务填充队列
3：其他进程将负责异步执行爬取任务，将任务状态更改为完成状态，并保存必要数据


增加中间表：如果任务正在执行 则1：记录任务id。2：任务正在执行的进程的进程号pid 。3：是否停止
重启时会将该表清空。如果暂停任务则将中间表中的记录删除，任务执行则记录该表。该表的数据个数与进程数对应。

任务状态分为：0初始状态，1：被扫描进程获取（每次启动程序将该状态改变为0），2：执行状态（任务被执行时的状态。）
3：暂停状态（该状态就会检查，断点字段是否会重新开始爬取） 4：完成状态（任务访问过所有url则记录为该状态）

需要改进的地方：
1：将爬取与解析进行代码结构分离
（爬取程序直接将爬取结果写入数据库即可，解析程序成为一个独立的模块）
2：待补充

后续改进方案。
将内容中的杂质符去掉，将没有爬取到content内容的url存储

1：数据库采用自己的mongodb，只将自己的解析数据入到相应的库即可。
2：抓取解析分离。抓取将html文件保存，解析将负责解析文件然后将解析的文件
3：

规则类型:
    1:前正则替换 (格式:  \<p\>\(来源[\s\S]*?\)\<\/p\>|yyy ), yyy为替换后内容,可为空(等同为删除内容).
    2:截取信息 (格式:  xxx|yyy ), 从 xxx 出现的位置开始截取,到 yyy 的位置截止, xxx,yyy不可以同时为空,但可以任一为空.
    3:替换信息 (格式:  xxx|yyy ), 把文字 xxx 替换成 yyy , yyy 为空 等同于删除, xxx不可以为空,但yyy可为空.
    4:后正则替换, 格式同前正则替换格式.

增加清洗规则页面和展示数据，需要编辑人员手动开始执行解析任务。
需要增加的工作：

1：数据展示页面
2: 编辑解析规则页面
3：编辑结束以后生成一个新的解析任务，开始执行解析操作
任务类型分为：抓取任务，解析任务
任务执行类型分为:周期任务，一次性任务。

数据库增加的字段：任务类型，任务执行类型，执行周期，上次执行结束时间  暂定这几项后续补充

